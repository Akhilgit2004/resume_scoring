{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.pipeline import EntityRuler\n",
        "from spacy.lang.en import English\n",
        "from spacy.tokens import Doc\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from spacy import displacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import jsonlines\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download(['stopwords','wordnet'])\n",
        "#warning\n",
        "import warnings\n",
        "import requests\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "import uuid\n",
        "import PyPDF2\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import mysql.connector\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "mydb = mysql.connector.connect(\n",
        "    host=\"localhost\",\n",
        "    user=\"root\",\n",
        "    password=\"password\",\n",
        "    database=\"testdb\"\n",
        ")\n",
        "\n",
        "cur=mydb.cursor(dictionary=True)\n",
        "\n",
        "resume = []\n",
        "job_desc = []\n",
        "\n",
        "def getvals(lst, tablename):\n",
        "    cur.execute(f\"SELECT * FROM {tablename}\")\n",
        "    res = cur.fetchall()\n",
        "    if tablename == \"resume\":\n",
        "\n",
        "        idres=1000\n",
        "    else:\n",
        "        idres=100\n",
        "    for row in res:\n",
        "        \n",
        "        lst.append({\n",
        "            \"ID\": idres,\n",
        "            f\"{tablename}_str\": row[\"resume_str\"] if tablename == \"resume\" else row[\"JD_str\"],\n",
        "            \"Category\": row[\"role\"]\n",
        "        })\n",
        "        idres+=1\n",
        "\n",
        "getvals(resume, \"resume\")\n",
        "getvals(job_desc, \"JD\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>resume_str</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000</td>\n",
              "      <td>Abhishek Sen\\nTest Engineer\\nSkills: Performan...</td>\n",
              "      <td>automation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1001</td>\n",
              "      <td>Aditi Sharma\\nSoftware Tester\\nSkills: Manual ...</td>\n",
              "      <td>automation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1002</td>\n",
              "      <td>Deepika Reddy\\nQA Automation Engineer\\nSkills:...</td>\n",
              "      <td>automation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1003</td>\n",
              "      <td>Aarav Mehta\\naarav.mehta@example.com | +91-987...</td>\n",
              "      <td>full-stack-dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1004</td>\n",
              "      <td>Divya Sharma\\ndivya.sharma@example.com | +91-9...</td>\n",
              "      <td>full-stack-dev</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     ID                                         resume_str        Category\n",
              "0  1000  Abhishek Sen\\nTest Engineer\\nSkills: Performan...      automation\n",
              "1  1001  Aditi Sharma\\nSoftware Tester\\nSkills: Manual ...      automation\n",
              "2  1002  Deepika Reddy\\nQA Automation Engineer\\nSkills:...      automation\n",
              "3  1003  Aarav Mehta\\naarav.mehta@example.com | +91-987...  full-stack-dev\n",
              "4  1004  Divya Sharma\\ndivya.sharma@example.com | +91-9...  full-stack-dev"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df_resume=pd.DataFrame(resume)\n",
        "df_JD=pd.DataFrame(job_desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset processing complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_spacy_model():\n",
        "    nlp = spacy.load('en_core_web_lg')\n",
        "    # Add entity ruler with overwrite enabled\n",
        "    ruler = nlp.add_pipe('entity_ruler', config={\"overwrite_ents\": True})\n",
        "    skill_pattern_path = r'/mnt/c/Users/malla/Downloads/extract_here/archive/Resume/jz_skill_patterns.jsonl'\n",
        "    nlp.get_pipe(\"entity_ruler\").from_disk(skill_pattern_path)\n",
        "    return nlp\n",
        "\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "def get_skills(text, nlp):\n",
        "\n",
        "    doc = nlp(text)\n",
        "    skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
        "    return skills\n",
        "\n",
        "def unique_skills(skills):\n",
        "\n",
        "    return list(set(skills))\n",
        "\n",
        "def clean_resume_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "def process_dataset(nlp, df):\n",
        "    clean_resumes = [clean_resume_text(resume) for resume in df[\"resume_str\"]]\n",
        "    df[\"Clean_Resume\"] = clean_resumes\n",
        "    df[\"skills\"] = df[\"Clean_Resume\"].str.lower().apply(lambda x: get_skills(x, nlp))\n",
        "    df[\"skills\"] = df[\"skills\"].apply(unique_skills)\n",
        "\n",
        "    print(\"Dataset processing complete.\")\n",
        "    return df\n",
        "\n",
        "df = process_dataset(nlp, df_resume)\n",
        "\n",
        "\n",
        "\n",
        "def extract_experience_years(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Pattern: \"3 - 5 years\", \"3-5 years\"\n",
        "    match_range = re.search(r'(\\d+)\\s*[-to]+\\s*(\\d+)\\s*(?:years|yrs)', text)\n",
        "    if match_range:\n",
        "        return int(match_range.group(2))  # Use upper bound\n",
        "\n",
        "    # Pattern: \"5+ years\", \"5+ yrs\"\n",
        "    match_plus = re.search(r'(\\d+)\\+\\s*(?:years|yrs)', text)\n",
        "    if match_plus:\n",
        "        return int(match_plus.group(1))\n",
        "\n",
        "    # Pattern: \"minimum of 3 years\", \"at least 4 years\"\n",
        "    match_min = re.search(r'(?:minimum of|at least)\\s+(\\d+)\\s*(?:years|yrs)', text)\n",
        "    if match_min:\n",
        "        return int(match_min.group(1))\n",
        "\n",
        "    # Pattern: \"3 years\", \"2 yrs\"\n",
        "    match_single = re.search(r'(\\d+)\\s*(?:years|yrs)', text)\n",
        "    if match_single:\n",
        "        return int(match_single.group(1))\n",
        "\n",
        "    # Fallback\n",
        "    return 0\n",
        "\n",
        "\n",
        "def calculate_combined_match_score(input_resume,job_description,nlp,model=SentenceTransformer('all-MiniLM-L6-v2'),skill_exact_weight=0.0,skill_semantic_weight=0.8,experience_weight=0.2):\n",
        "\n",
        "    input_resume_cleaned = clean_resume_text(input_resume.lower())\n",
        "    job_description_cleaned = clean_resume_text(job_description.lower())\n",
        "\n",
        "    resume_skills = [s.lower().strip() for s in unique_skills(get_skills(input_resume_cleaned, nlp))]\n",
        "    jd_skills = [s.lower().strip() for s in unique_skills(get_skills(job_description_cleaned, nlp))]\n",
        "\n",
        "    # --- Exact Match ---\n",
        "    if jd_skills:\n",
        "        exact_matches = set(resume_skills).intersection(set(jd_skills))\n",
        "        skill_match_exact = len(exact_matches) / len(jd_skills)\n",
        "    else:\n",
        "        skill_match_exact = 0\n",
        "\n",
        "    # --- Semantic Match ---\n",
        "    if resume_skills and jd_skills:\n",
        "        resume_vec = model.encode(\" \".join(resume_skills))\n",
        "        jd_vec = model.encode(\" \".join(jd_skills))\n",
        "        sim = cosine_similarity([resume_vec], [jd_vec])[0][0]\n",
        "        skill_match_semantic = min(sim * 1.5, 1.0)  # Boost and cap at 1.0\n",
        "    else:\n",
        "        skill_match_semantic = 0\n",
        "\n",
        "    # --- Experience Match ---\n",
        "    req_exp = extract_experience_years(job_description)\n",
        "    res_exp = extract_experience_years(input_resume)\n",
        "\n",
        "    if req_exp > 0:\n",
        "        experience_match = min(res_exp / req_exp, 1.0)\n",
        "    elif res_exp > 0:\n",
        "        experience_match = 0.5  # Fallback\n",
        "    else:\n",
        "        experience_match = 0\n",
        "\n",
        "    total = (\n",
        "        skill_match_exact * skill_exact_weight +\n",
        "        skill_match_semantic * skill_semantic_weight +\n",
        "        experience_match * experience_weight\n",
        "    ) * 100\n",
        "\n",
        "    return round(total, 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top Resume Scores for the job of automation\n",
            "1. Resume ID: 1019 — Score: 88.4900\n",
            "2. Resume ID: 1000 — Score: 87.5800\n",
            "3. Resume ID: 1011 — Score: 85.0500\n",
            "4. Resume ID: 1009 — Score: 81.5400\n",
            "5. Resume ID: 1010 — Score: 74.5400\n",
            "6. Resume ID: 1012 — Score: 74.4500\n",
            "7. Resume ID: 1016 — Score: 71.3700\n",
            "8. Resume ID: 1018 — Score: 70.1900\n",
            "9. Resume ID: 1014 — Score: 68.7700\n",
            "10. Resume ID: 1013 — Score: 67.4800\n"
          ]
        }
      ],
      "source": [
        "jd_input = input(\"Select the role: \").lower()\n",
        "\n",
        "# Reset index to use iloc safely\n",
        "resumes = df_resume[df_resume[\"Category\"] == jd_input][[\"ID\", \"resume_str\"]].reset_index(drop=True)\n",
        "jds = df_JD[df_JD[\"Category\"] == jd_input][[\"ID\", \"JD_str\"]].reset_index(drop=True)\n",
        "\n",
        "final_scores = []\n",
        "\n",
        "for i in range(len(jds)):\n",
        "    for j in range(len(resumes)):\n",
        "        jd_text = jds.iloc[i][\"JD_str\"]\n",
        "        res_text = resumes.iloc[j][\"resume_str\"]\n",
        "        score = calculate_combined_match_score(res_text, jd_text, nlp)\n",
        "\n",
        "        res_id = resumes.iloc[j][\"ID\"]\n",
        "        jd_id = jds.iloc[i][\"ID\"]\n",
        "\n",
        "        final_scores.append((jd_id, res_id, score))\n",
        "\n",
        "# Sort by score descending\n",
        "top_10 = sorted(final_scores, key=lambda x: x[2], reverse=True)[:10]\n",
        "\n",
        "# Print results\n",
        "print(\"\\nTop Resume Scores for the job of\",jd_input)\n",
        "for rank, (jd_id, res_id, score) in enumerate(top_10, 1):\n",
        "    print(f\"{rank}. Resume ID: {res_id} — Score: {score:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "myvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
